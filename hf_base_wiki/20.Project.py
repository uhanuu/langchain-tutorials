# ì¸ê³µì§€ëŠ¥ PDF Q&A ì±—ë´‡ í”„ë¡œì íŠ¸
# gradio: pip install gradio (https://www.gradio.app/guides/themes)

import gradio as gr
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_text_splitters import CharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.runnables import RunnablePassthrough

load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini")

text_splitter = CharacterTextSplitter(
  chunk_size = 1000,
  chunk_overlap=100
)

hf_embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")

message = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì—…ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥ì„ í† ëŒ€ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë§Œì•½, ë¬¸ë°±ì—ì„œ ë‹µë³€ì„ ìœ„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ 'ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' ë¼ê³  ë‹µí•˜ì„¸ìš”.
ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

## ì£¼ì–´ì§„ ë¬¸ë§¥: 
{context}

## ì‚¬ìš©ì ì§ˆë¬¸:
{input}
"""

prompt_template = ChatPromptTemplate.from_messages([
    ("human", message)
])

parser = StrOutputParser()
db = None
retriever = None
rag_chain = None

def load_pdf(file):
  global db, retriever, rag_chain
  
  loader = PyPDFLoader(file.name)
  docs = loader.load_and_split(text_splitter=text_splitter)

  db = FAISS.from_documents(docs, hf_embeddings)
  retriever = db.as_retriever(search_kwargs={"k":3})

  data = {
    "context": retriever,
    "input": RunnablePassthrough()
  }
  rag_chain = data | prompt_template | llm | parser

  return "PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œ ë° ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."



def answer_question(question):
  if rag_chain is None:
    return "PDF íŒŒì¼ì„ ì—…ë¡œë“œ í•˜ì„¸ìš”."
  return rag_chain.invoke(question)

with gr.Blocks(
  theme=gr.themes.Soft()) as demo:
  gr.Markdown("""
  # ğŸ“š ì¸ê³µì§€ëŠ¥ PDF Q&A ì±—ë´‡
  **PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.**
  """)

  with gr.Row():
    with gr.Column(scale=1):
      file_input = gr.File(label="ğŸ“‚ PDF íŒŒì¼ ì—…ë¡œë“œ")
      upload_button = gr.Button("ğŸ“¤ ì—…ë¡œë“œ ë° ì²˜ë¦¬")

    with gr.Column(scale=2):
      status_output = gr.Textbox(label="ğŸ“¢ ìƒíƒœ ë©”ì‹œì§€")
      question_input = gr.Textbox(label="ğŸ™‹ğŸ» ì§ˆë¬¸ ì…ë ¥", placeholder="ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì ì–´ì£¼ì„¸ìš”.")
      submit_button = gr.Button("ğŸ¤– ë‹µë³€ ë°›ê¸°")
      answer_output = gr.Textbox(label="ğŸ“ AI ë‹µë³€")
  
  upload_button.click(load_pdf, inputs=file_input, outputs=status_output)
  submit_button.click(answer_question, inputs=question_input, outputs=answer_output)

demo.launch()